# Python Cheat Sheet
1. Python String Formatting
2. Python Comprehensions
3. 머신러닝 종류
> 3.1. 선형회귀모델  
> 3.2. 의사결정나무  
> 3.3. 랜덤포레스트  
> 3.4. XGBOOST 회귀  
> 3.5. K-FOLD 교차검증
4. 성능 평가 하는 법


# Python String Formatting
---
## % operator
```sql
>>> name = 'Pete'
>>> 'Hello %s' % name
# "Hello Pete"
```
We can use the %d format specifier to convert an int value to a string:
```sql
>>> num = 5
>>> 'I have %d apples' % num
# "I have 5 apples"
```

## str.format
Python 3 introduced a new way to do string formatting that was later back-ported to Python 2.7. This makes the syntax for string formatting more regular.
```sql
>>> name = 'John'
>>> age = 20

>>> "Hello I'm {}, my age is {}".format(name, age)
# "Hello I'm John, my age is 20"

>>> "Hello I'm {0}, my age is {1}".format(name, age)
# "Hello I'm John, my age is 20"
```

## Formatted String Literals or f-Strings
If your are using Python 3.6+, string f-Strings are the recommended way to format strings.
```sql
>>> name = 'Elizabeth'
>>> f'Hello {name}!'
# 'Hello Elizabeth!'
```
It is even possible to do inline arithmetic with it:
```sql
>>> a = 5
>>> b = 10
>>> f'Five plus ten is {a + b} and not {2 * (a + b)}.'
# 'Five plus ten is 15 and not 30.'
```

## Multiline f-Strings
```sql
>>> name = 'Robert'
>>> messages = 12
>>> (
... f'Hi, {name}. '
... f'You have {messages} unread messages'
... )
# 'Hi, Robert. You have 12 unread messages'
```

## The = specifier
This will print the expression and its value:
```sql
>>> from datetime import datetime
>>> now = datetime.now().strftime("%b/%d/%Y - %H:%M:%S")
>>> f'date and time: {now=}'
# "date and time: now='Nov/14/2022 - 20:50:01'"
```

## Adding spaces or characters
```sql
>>> f"{name.upper() = :-^20}"
# 'name.upper() = -------ROBERT-------'
>>>
>>> f"{name.upper() = :^20}"
# 'name.upper() =        ROBERT       '
>>>
>>> f"{name.upper() = :20}"
# 'name.upper() = ROBERT              '
```

## Formatting Digits
Adding thousands separator
```sql
>>> a = 10000000
>>> f"{a:,}"
# '10,000,000'
```
Rounding
```sql
>>> a = 3.1415926
>>> f"{a:.2f}"
# '3.14'
```
Showing as Percentage
```sql
>>> a = 0.816562
>>> f"{a:.2%}"
# '81.66%'
```

## Number formatting table
Number|Format|Output|묘사|description
---:|:---:|:---:|:---:|:---
3.1415926|{:.2f}|3.14|소수점 이하 2자리 부동 소수점 형식 지정|Format float 2 decimal places
3.1415926|{:+.2f}|+3.14|기호가 있는 소수점 이하 2자리 형식|Format float 2 decimal places with sign
-1|{:+.2f}|-1.00|기호가 있는 소수점 이하 2자리 형식|Format float 2 decimal places with sign
2.71828|{:.0f}|3|소수점 이하 자릿수가 없는 부동 소수점 형식 지정|Format float with no decimal places
4|{:0>2d}|04|0이 있는 패드 번호(왼쪽 패딩, 너비 2)|Pad number with zeros (left padding, width 2)
4|{:x<4d}|4xxx|패드 번호와 x(오른쪽 패딩, 폭 4)|Pad number with x’s (right padding, width 4)
10|{:x<4d}|10xx|패드 번호와 x(오른쪽 패딩, 폭 4)|Pad number with x’s (right padding, width 4)
1000000|{:,}|1,000,000|쉼표 구분 기호가 있는 숫자 형식|Number format with comma separator
0.35|{:.2%}|35.00%|형식 백분율|Format percentage
1000000000|{:.2e}|1.00e+09|지수 표기법|Exponent notation
11|{:11d}|11|오른쪽 맞춤(기본값, 너비 10)|Right-aligned (default, width 10)
11|{:<11d}|11|왼쪽 정렬(너비 10)|Left-aligned (width 10)
11|{:^11d}|11|중앙 정렬(너비 10)|Center aligned (width 10)

## Template Strings
A simpler and less powerful mechanism, but it is recommended when handling strings generated by users. Due to their reduced complexity, template strings are a safer choice.
```sql
>>> from string import Template
>>> name = 'Elizabeth'
>>> t = Template('Hey $name!')
>>> t.substitute(name=name)
# 'Hey Elizabeth!'
```

# Python Comprehensions
---
List Comprehensions are a special kind of syntax that let us create lists out of other lists, and are incredibly useful when dealing with numbers and with one or two levels of nested for loops.

## List comprehension
This is how we create a new list from an existing collection with a For Loop:
```sql
>>> names = ['Charles', 'Susan', 'Patrick', 'George']

>>> new_list = []
>>> for n in names:
...     new_list.append(n)
...
>>> new_list
# ['Charles', 'Susan', 'Patrick', 'George']
```
And this is how we do the same with a List Comprehension:
```sql
>>> names = ['Charles', 'Susan', 'Patrick', 'George']

>>> new_list = [n for n in names]
>>> new_list
# ['Charles', 'Susan', 'Patrick', 'George']
```
We can do the same with numbers:
```sql
>>> n = [(a, b) for a in range(1, 3) for b in range(1, 3)]
>>> n
# [(1, 1), (1, 2), (2, 1), (2, 2)]
```

## Adding conditionals
If we want to have only the names that start with C, with a for loop, we would do it like this:'new_list'
```sql
>>> names = ['Charles', 'Susan', 'Patrick', 'George', 'Carol']

>>> new_list = []
>>> for n in names:
...     if n.startswith('C'):
...         new_list.append(n)
...
>>> print(new_list)
# ['Charles', 'Carol']
```
In a List Comprehension, we add the statement at the end:'if'
```sql
>>> new_list = [n for n in names if n.startswith('C')]
>>> print(new_list)
# ['Charles', 'Carol']
```

## Set comprehension
```sql
>>> b = {"abc", "def"}
>>> {s.upper() for s in b}
{"ABC", "DEF"}
```

## Dict comprehension
```sql
>>> c = {'name': 'Pooka', 'age': 5}
>>> {v: k for k, v in c.items()}
{'Pooka': 'name', 5: 'age'}
```
A List comprehension can be generated from a dictionary:
```sql
>>> c = {'name': 'Pooka', 'first_name': 'Oooka'}
>>> ["{}:{}".format(k.upper(), v.upper()) for k, v in c.items()]
['NAME:POOKA', 'FIRST_NAME:OOOKA']
```

# 머신러닝 종류
```sql
# train, test 나누기
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

#min-max scaling (정규화, Normalization)
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_normal = scaler.fit_transform(X_train)

#valid 만들기
x_train, x_valid, y_train, y_valid = train_test_split(X_normal, y_train, test_size=0.2, random_state=1)
```
## 선형회귀모델
```sql
from sklearn.linear_model import LinearRegression

linear = LinearRegression()
linear.fit(x_train, y_train)
# LinearRegression()
```
```sql
y_pred_li = linear.predict(x_train)
```
```sql
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score

lin_R2 = r2_score(y_train, y_pred_li)
lin_mae = mean_absolute_error(y_train, y_pred_li)
print(lin_R2)
print(lin_mae)
# 0.6246128122849793
# 50991.49590631308
```
```sql
y_pred_li = linear.predict(x_valid)
```
```sql
lin_R2 = r2_score(y_valid, y_pred_li)
lin_mae = mean_absolute_error(y_valid, y_pred_li)
print(lin_R2)
print(lin_mae)
# 0.615093103430377
# 52231.92463744161
```
## 의사결정나무
```sql
from sklearn.tree import DecisionTreeRegressor

tree = DecisionTreeRegressor()
tree.fit(x_train, y_train)
# DecisionTreeRegressor()
```
```sql
y_pred_tr = tree.predict(x_train)

lin_R2 = r2_score(y_train, y_pred_tr)
lin_mae = mean_absolute_error(y_train, y_pred_tr)
print(lin_R2)
print(lin_mae)
# 1.0
# 0.0
```
```sql
y_pred_tr = tree.predict(x_valid)
```
```sql
tree_R2 = r2_score(y_valid, y_pred_tr)
tree_mae = mean_absolute_error(y_valid, y_pred_tr)
print(tree_R2)
print(tree_mae)
# 0.6040317121249402
# 45843.157129881925
```

## 랜덤포레스트
```sql
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor()
rf.fit(x_train, y_train)
# RandomForestRegressor()
```
```sql
y_pred_rf = tree.predict(x_train)

rf_R2 = r2_score(y_train, y_pred_rf)
rf_mae = mean_absolute_error(y_train, y_pred_rf)
print(rf_R2)
print(rf_mae)
# 1.0
# 0.0
```
```sql
y_pred_rf = tree.predict(x_valid)
```
```sql
rf_R2 = r2_score(y_valid, y_pred_rf)
rf_mae = mean_absolute_error(y_valid, y_pred_rf)
print(rf_R2)
print(rf_mae)
# 0.6040317121249402
# 45843.157129881925
```

## XGBoost 회귀
```sql
import xgboost

xgb_model = xgboost.XGBRegressor()
xgb_model.fit(x_train, y_train)
```
```sql
# OUTPUT
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,
             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,
             importance_type='gain', interaction_constraints='',
             learning_rate=0.300000012, max_delta_step=0, max_depth=6,
             min_child_weight=1, missing=nan, monotone_constraints='()',
             n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,
             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,
             tree_method='exact', validate_parameters=1, verbosity=None)
```
```sql
y_pred_xgb = xgb_model.predict(x_train)

xgb_R2 = r2_score(y_train, y_pred_xgb)
xgb_mae = mean_absolute_error(y_train, y_pred_xgb)
print(xgb_R2)
print(xgb_mae)
# 0.9390500039169059
# 20266.895483932592
```
```sql
y_pred_xgb = xgb_model.predict(x_valid)
```
```sql
xgb_R2 = r2_score(y_valid, y_pred_xgb)
xgb_mae = mean_absolute_error(y_valid, y_pred_xgb)
print(xgb_R2)
print(xgb_mae)
# 0.8195479642727931
# 32955.129073001815
```

## k-fold 교차검증
```sql
def display_scores(model,scores):
    print('<<',model, '모델 평가 결과 >>')
    print('평균 RMSE:', scores.mean())
    print('표준편차:', scores.std())
```
```sql
import numpy as np
from sklearn.model_selection import cross_val_score

tree_scores = cross_val_score(tree, x_valid, y_valid, scoring='neg_mean_squared_error', cv=10)
tree_rmse_scores = np.sqrt(-tree_scores)

lin_scores = cross_val_score(linear, x_valid, y_valid, scoring='neg_mean_squared_error', cv=10)
lin_rmse_scores = np.sqrt(-lin_scores)

rf_scores = cross_val_score(rf, x_valid, y_valid, scoring='neg_mean_squared_error', cv=10)
rf_rmse_scores = np.sqrt(-rf_scores)

xgb_scores = cross_val_score(xgb_model, x_valid, y_valid, scoring='neg_mean_squared_error', cv=10)
xgb_rmse_scores = np.sqrt(-xgb_scores)
```
```sql
import numpy as np
from sklearn.model_selection import cross_val_score

tree_scores = cross_val_score(tree, x_valid, y_valid, scoring='neg_mean_squared_error', cv=10)
tree_rmse_scores = np.sqrt(-tree_scores)

lin_scores = cross_val_score(linear, x_valid, y_valid, scoring='neg_mean_squared_error', cv=10)
lin_rmse_scores = np.sqrt(-lin_scores)

rf_scores = cross_val_score(rf, x_valid, y_valid, scoring='neg_mean_squared_error', cv=10)
rf_rmse_scores = np.sqrt(-rf_scores)

xgb_scores = cross_val_score(xgb_model, x_valid, y_valid, scoring='neg_mean_squared_error', cv=10)
xgb_rmse_scores = np.sqrt(-xgb_scores)
```
```sql
# OUTPUT
<< 선형회귀 모델 평가 결과 >>
평균 RMSE: 70134.82258901293
표준편차: 3135.2154009929136


<< 의사결정나무 모델 평가 결과 >>
평균 RMSE: 77048.8584526432
표준편차: 3991.6789207226984


<< 랜덤포레스트 모델 평가 결과 >>
평균 RMSE: 57317.818981409866
표준편차: 1593.355992301959


<< XGBoost 모델 평가 결과 >>
평균 RMSE: 54391.60931727962
표준편차: 2778.9638841159435
```
